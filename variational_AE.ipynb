{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "variational AE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/manikanthM/fahion-mnist-/blob/master/variational_AE.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "eyEyykq7Z24-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import keras \n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import load_model,Sequential,Model\n",
        "from time import time\n",
        "from sklearn.cluster import KMeans\n",
        "from keras import callbacks\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Input, Lambda, Layer, Add, Multiply\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "from scipy.misc import imread\n",
        "from sklearn.metrics import accuracy_score, normalized_mutual_info_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GX9KHIfuae0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIUIEEiGavdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=x_train/255\n",
        "x_test=x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MPY_CqOia_DX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(-1,784)\n",
        "x_test=x_test.reshape(-1,784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9F4FzpwZbJ3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_img=Input(shape=(784,))\n",
        "encoded=Dense(300,activation='relu')(input_img)\n",
        "z_mu=Dense(10)(encoded)\n",
        "z_logsigma=Dense(10)(encoded)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kThGiYBtb5JO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class KLDivergenceLayer(Layer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mu, log_sigma = inputs\n",
        "\n",
        "        kl_batch = - .5 * K.sum(1 + log_sigma -\n",
        "                                K.square(mu) -\n",
        "                                K.exp(log_sigma), axis=-1)\n",
        "\n",
        "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
        "\n",
        "        return inputs\n",
        "\n",
        "z_mu, z_logsigma = KLDivergenceLayer()([z_mu, z_logsigma])\n",
        "z_sigma = Lambda(lambda t: K.exp(.5*t))(z_logsigma)\n",
        "\n",
        "eps = Input(tensor=K.random_normal(shape=(K.shape(input_img)[0],10)))\n",
        "z_eps = Multiply()([z_sigma, eps])\n",
        "z = Add()([z_mu, z_eps])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GjNOhdEjcZaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder = Sequential([\n",
        "    Dense(300, input_dim=10, activation='relu'),\n",
        "    Dense(784, activation='sigmoid')\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pAajmkUPdNOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoded=decoder(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "819Gi1h6dRkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder = Model([input_img, eps], decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lafnf-K7dY67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "e5dfb394-21f0-4218-f982-e624a2d19668"
      },
      "cell_type": "code",
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 784)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 300)          235500      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 10)           3010        dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 10)           3010        dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "kl_divergence_layer_8 (KLDiverg [(None, 10), (None,  0           dense_13[0][0]                   \n",
            "                                                                 dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 10)           0           kl_divergence_layer_8[0][1]      \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 10)           0           lambda_2[0][0]                   \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10)           0           kl_divergence_layer_8[0][0]      \n",
            "                                                                 multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 784)          239284      add_2[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 480,804\n",
            "Trainable params: 480,804\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uyikEa0qdciQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nll(y_true, y_pred):\n",
        "  return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lMj-qRADdmey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss=nll)\n",
        "estop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6N3vCi9NeUlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7449
        },
        "outputId": "98020060-a44d-431b-9ebd-97cefec1abff"
      },
      "cell_type": "code",
      "source": [
        "train_history = autoencoder.fit(x_train, x_train, epochs=500, batch_size=2048, validation_data=(x_test, x_test), callbacks=[estop])\n",
        "autoencoder.save('mymodel.h5')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 441.3350 - val_loss: 356.8872\n",
            "Epoch 2/500\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 329.0771 - val_loss: 311.5986\n",
            "Epoch 3/500\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 300.3763 - val_loss: 292.0383\n",
            "Epoch 4/500\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 285.1070 - val_loss: 280.7912\n",
            "Epoch 5/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 276.7622 - val_loss: 275.0425\n",
            "Epoch 6/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 271.3717 - val_loss: 271.6019\n",
            "Epoch 7/500\n",
            "59392/60000 [============================>.] - ETA: 0s - loss: 267.9343"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 7s 118us/step - loss: 267.9250 - val_loss: 267.7109\n",
            "Epoch 8/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 264.9681 - val_loss: 265.4549\n",
            "Epoch 9/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 262.9642 - val_loss: 263.5122\n",
            "Epoch 10/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 261.3453 - val_loss: 261.8555\n",
            "Epoch 11/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 259.7574 - val_loss: 261.6870\n",
            "Epoch 12/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 258.6648 - val_loss: 259.7736\n",
            "Epoch 13/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 257.4811 - val_loss: 258.5456\n",
            "Epoch 14/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 256.3332 - val_loss: 257.5112\n",
            "Epoch 15/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 255.7122 - val_loss: 256.7205\n",
            "Epoch 16/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 255.0020 - val_loss: 256.0146\n",
            "Epoch 17/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 254.2187 - val_loss: 255.5238\n",
            "Epoch 18/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 253.4704 - val_loss: 254.8294\n",
            "Epoch 19/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 253.0508 - val_loss: 254.9224\n",
            "Epoch 20/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 252.6412 - val_loss: 254.0589\n",
            "Epoch 21/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 252.1282"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 118us/step - loss: 251.9818 - val_loss: 253.3893\n",
            "Epoch 22/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 251.6004 - val_loss: 253.2936\n",
            "Epoch 23/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 251.1617 - val_loss: 252.5723\n",
            "Epoch 24/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 250.6850 - val_loss: 252.4655\n",
            "Epoch 25/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 250.4937 - val_loss: 253.2692\n",
            "Epoch 26/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 250.3852 - val_loss: 251.7582\n",
            "Epoch 27/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 249.8818 - val_loss: 251.3136\n",
            "Epoch 28/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 249.3262"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 249.4093 - val_loss: 251.0167\n",
            "Epoch 29/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 249.1277 - val_loss: 250.7392\n",
            "Epoch 30/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 248.8945 - val_loss: 250.4281\n",
            "Epoch 31/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 248.7418 - val_loss: 250.3077\n",
            "Epoch 32/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 248.7470 - val_loss: 250.7042\n",
            "Epoch 33/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 248.4313 - val_loss: 249.8373\n",
            "Epoch 34/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 247.9971 - val_loss: 249.5932\n",
            "Epoch 35/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 247.8161"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 247.8604 - val_loss: 249.3838\n",
            "Epoch 36/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 247.6679 - val_loss: 249.2463\n",
            "Epoch 37/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 247.7166 - val_loss: 249.1985\n",
            "Epoch 38/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 247.2619 - val_loss: 248.8703\n",
            "Epoch 39/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 247.1550 - val_loss: 248.7365\n",
            "Epoch 40/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 247.0228 - val_loss: 248.5554\n",
            "Epoch 41/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 246.8384 - val_loss: 249.4648\n",
            "Epoch 42/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 246.5876"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 246.8191 - val_loss: 248.3832\n",
            "Epoch 43/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 246.8471 - val_loss: 248.6196\n",
            "Epoch 44/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 246.4322 - val_loss: 248.0758\n",
            "Epoch 45/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 246.2177 - val_loss: 247.9502\n",
            "Epoch 46/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 246.1488 - val_loss: 247.8144\n",
            "Epoch 47/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 246.1977 - val_loss: 247.8481\n",
            "Epoch 48/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.9115 - val_loss: 247.5360\n",
            "Epoch 49/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 245.2600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.7678 - val_loss: 247.4113\n",
            "Epoch 50/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.5718 - val_loss: 247.7229\n",
            "Epoch 51/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.5858 - val_loss: 247.2638\n",
            "Epoch 52/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.3821 - val_loss: 247.2174\n",
            "Epoch 53/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.3508 - val_loss: 247.1398\n",
            "Epoch 54/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.4539 - val_loss: 247.0079\n",
            "Epoch 55/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.1272 - val_loss: 247.0987\n",
            "Epoch 56/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 245.2845"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.0675 - val_loss: 246.7729\n",
            "Epoch 57/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.9675 - val_loss: 246.6496\n",
            "Epoch 58/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.8502 - val_loss: 246.6929\n",
            "Epoch 59/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 245.0071 - val_loss: 246.6023\n",
            "Epoch 60/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 244.7347 - val_loss: 246.9376\n",
            "Epoch 61/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.6086 - val_loss: 246.5948\n",
            "Epoch 62/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.6241 - val_loss: 246.2793\n",
            "Epoch 63/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 244.4684"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.3923 - val_loss: 246.3859\n",
            "Epoch 64/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.3018 - val_loss: 246.1626\n",
            "Epoch 65/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.3844 - val_loss: 246.3010\n",
            "Epoch 66/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.2544 - val_loss: 246.1819\n",
            "Epoch 67/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.1299 - val_loss: 246.3518\n",
            "Epoch 68/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 244.1116 - val_loss: 245.8512\n",
            "Epoch 69/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.9770 - val_loss: 245.9926\n",
            "Epoch 70/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 243.8279"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.9629 - val_loss: 245.7769\n",
            "Epoch 71/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 243.9501 - val_loss: 246.2219\n",
            "Epoch 72/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.9534 - val_loss: 245.7905\n",
            "Epoch 73/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.7760 - val_loss: 245.5654\n",
            "Epoch 74/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.6283 - val_loss: 245.4159\n",
            "Epoch 75/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.5851 - val_loss: 245.4235\n",
            "Epoch 76/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.6726 - val_loss: 245.5318\n",
            "Epoch 77/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 243.7622"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 243.4788 - val_loss: 245.7804\n",
            "Epoch 78/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.4497 - val_loss: 245.6632\n",
            "Epoch 79/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.3091 - val_loss: 245.2887\n",
            "Epoch 80/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 243.3629 - val_loss: 245.3111\n",
            "Epoch 81/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.3100 - val_loss: 245.1349\n",
            "Epoch 82/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.4449 - val_loss: 245.0599\n",
            "Epoch 83/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.1113 - val_loss: 245.3771\n",
            "Epoch 84/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 243.4269"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 243.4343 - val_loss: 245.0472\n",
            "Epoch 85/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 243.0913 - val_loss: 244.8954\n",
            "Epoch 86/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.9280 - val_loss: 244.8869\n",
            "Epoch 87/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.9562 - val_loss: 244.7348\n",
            "Epoch 88/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.9433 - val_loss: 245.4517\n",
            "Epoch 89/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.8485 - val_loss: 244.7482\n",
            "Epoch 90/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.9841 - val_loss: 244.7930\n",
            "Epoch 91/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 242.9114"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.8935 - val_loss: 244.6353\n",
            "Epoch 92/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.6459 - val_loss: 244.6616\n",
            "Epoch 93/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.5883 - val_loss: 244.7042\n",
            "Epoch 94/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.5838 - val_loss: 244.6819\n",
            "Epoch 95/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.5626 - val_loss: 244.4785\n",
            "Epoch 96/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.5318 - val_loss: 244.6157\n",
            "Epoch 97/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.4194 - val_loss: 244.3818\n",
            "Epoch 98/500\n",
            "28672/60000 [=============>................] - ETA: 3s - loss: 242.7678"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.3911 - val_loss: 244.4060\n",
            "Epoch 99/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.5065 - val_loss: 244.4952\n",
            "Epoch 100/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.3418 - val_loss: 244.2931\n",
            "Epoch 101/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.4321 - val_loss: 245.0055\n",
            "Epoch 102/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.5935 - val_loss: 244.4714\n",
            "Epoch 103/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.2555 - val_loss: 244.3517\n",
            "Epoch 104/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.2397 - val_loss: 244.3578\n",
            "Epoch 105/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 242.2396"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.1101 - val_loss: 244.1379\n",
            "Epoch 106/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.1169 - val_loss: 244.7230\n",
            "Epoch 107/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 242.1391 - val_loss: 244.1323\n",
            "Epoch 108/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.9870 - val_loss: 244.0005\n",
            "Epoch 109/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.0978 - val_loss: 243.9581\n",
            "Epoch 110/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.9506 - val_loss: 244.1850\n",
            "Epoch 111/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.8435 - val_loss: 244.0690\n",
            "Epoch 112/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 241.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 242.0440 - val_loss: 243.8971\n",
            "Epoch 113/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.8928 - val_loss: 243.7453\n",
            "Epoch 114/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.7668 - val_loss: 243.7389\n",
            "Epoch 115/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 241.9635 - val_loss: 243.8381\n",
            "Epoch 116/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.7102 - val_loss: 243.8003\n",
            "Epoch 117/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.6968 - val_loss: 243.5541\n",
            "Epoch 118/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.7405 - val_loss: 244.1571\n",
            "Epoch 119/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 241.8978"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.6688 - val_loss: 243.5650\n",
            "Epoch 120/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.6830 - val_loss: 243.6183\n",
            "Epoch 121/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 241.5883 - val_loss: 243.6267\n",
            "Epoch 122/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.6098 - val_loss: 244.0771\n",
            "Epoch 123/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 241.6426 - val_loss: 243.5915\n",
            "Epoch 124/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.7105 - val_loss: 243.5145\n",
            "Epoch 125/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.4725 - val_loss: 243.5241\n",
            "Epoch 126/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 241.6340"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 118us/step - loss: 241.5347 - val_loss: 243.6179\n",
            "Epoch 127/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.4035 - val_loss: 243.4507\n",
            "Epoch 128/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.5806 - val_loss: 243.4806\n",
            "Epoch 129/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.3424 - val_loss: 243.4359\n",
            "Epoch 130/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 241.2998 - val_loss: 243.3296\n",
            "Epoch 131/500\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 241.4134 - val_loss: 243.9415\n",
            "Epoch 132/500\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 241.3316 - val_loss: 243.2425\n",
            "Epoch 133/500\n",
            "28672/60000 [=============>................] - ETA: 2s - loss: 241.3289"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 5s 81us/step - loss: 241.2077 - val_loss: 243.4105\n",
            "Epoch 134/500\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 241.2213 - val_loss: 243.3591\n",
            "Epoch 135/500\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 241.2498 - val_loss: 243.1890\n",
            "Epoch 136/500\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 241.1968 - val_loss: 243.6133\n",
            "Epoch 137/500\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 241.4490 - val_loss: 243.1955\n",
            "Epoch 138/500\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 241.1009 - val_loss: 243.1956\n",
            "Epoch 139/500\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 241.1229 - val_loss: 243.2913\n",
            "Epoch 140/500\n",
            "34816/60000 [================>.............] - ETA: 1s - loss: 241.1702"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 5s 84us/step - loss: 241.0261 - val_loss: 243.0568\n",
            "Epoch 141/500\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 241.0769 - val_loss: 243.1108\n",
            "Epoch 142/500\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 241.1421 - val_loss: 242.9675\n",
            "Epoch 143/500\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 240.9760 - val_loss: 243.1676\n",
            "Epoch 144/500\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 240.9490 - val_loss: 242.9434\n",
            "Epoch 145/500\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 240.9863 - val_loss: 243.4067\n",
            "Epoch 146/500\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 241.2061 - val_loss: 242.9594\n",
            "Epoch 147/500\n",
            "36864/60000 [=================>............] - ETA: 1s - loss: 240.7794"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 5s 81us/step - loss: 241.0022 - val_loss: 242.8391\n",
            "Epoch 148/500\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 240.8173 - val_loss: 243.0882\n",
            "Epoch 149/500\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 240.9154 - val_loss: 242.8980\n",
            "Epoch 150/500\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 240.7882 - val_loss: 242.8255\n",
            "Epoch 151/500\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 240.8052 - val_loss: 242.9822\n",
            "Epoch 152/500\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 240.8348 - val_loss: 242.9863\n",
            "Epoch 153/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.8764 - val_loss: 243.3074\n",
            "Epoch 154/500\n",
            "32768/60000 [===============>..............] - ETA: 3s - loss: 240.6556"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.8261 - val_loss: 243.0710\n",
            "Epoch 155/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.6886 - val_loss: 242.6331\n",
            "Epoch 156/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.6315 - val_loss: 242.6912\n",
            "Epoch 157/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.6950 - val_loss: 242.8448\n",
            "Epoch 158/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.8524 - val_loss: 242.7400\n",
            "Epoch 159/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.6436 - val_loss: 242.7391\n",
            "Epoch 160/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.7007 - val_loss: 242.8354\n",
            "Epoch 161/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 240.7329"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.5919 - val_loss: 242.5869\n",
            "Epoch 162/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.6290 - val_loss: 242.7651\n",
            "Epoch 163/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.5853 - val_loss: 242.5756\n",
            "Epoch 164/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.4528 - val_loss: 242.8982\n",
            "Epoch 165/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.5288 - val_loss: 243.2612\n",
            "Epoch 166/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.6160 - val_loss: 242.5109\n",
            "Epoch 167/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.4317 - val_loss: 242.4947\n",
            "Epoch 168/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 240.4844"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.6694 - val_loss: 242.8251\n",
            "Epoch 169/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.5504 - val_loss: 242.6798\n",
            "Epoch 170/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.3691 - val_loss: 242.4296\n",
            "Epoch 171/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.4065 - val_loss: 242.5898\n",
            "Epoch 172/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.3773 - val_loss: 242.6994\n",
            "Epoch 173/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.5222 - val_loss: 242.6257\n",
            "Epoch 174/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.3006 - val_loss: 242.3879\n",
            "Epoch 175/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 240.3359"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.3792 - val_loss: 242.4795\n",
            "Epoch 176/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.3253 - val_loss: 242.5434\n",
            "Epoch 177/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.3411 - val_loss: 242.3256\n",
            "Epoch 178/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.2893 - val_loss: 242.5859\n",
            "Epoch 179/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.3386 - val_loss: 242.7131\n",
            "Epoch 180/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.3063 - val_loss: 242.2493\n",
            "Epoch 181/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.1734 - val_loss: 243.1280\n",
            "Epoch 182/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 240.2721"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.3685 - val_loss: 242.2693\n",
            "Epoch 183/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.2608 - val_loss: 242.2480\n",
            "Epoch 184/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.1764 - val_loss: 242.6692\n",
            "Epoch 185/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.2588 - val_loss: 242.1549\n",
            "Epoch 186/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.1645 - val_loss: 242.2045\n",
            "Epoch 187/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.1781 - val_loss: 242.3336\n",
            "Epoch 188/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0963 - val_loss: 242.2674\n",
            "Epoch 189/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 240.1060"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0242 - val_loss: 242.4769\n",
            "Epoch 190/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.1531 - val_loss: 242.1550\n",
            "Epoch 191/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.1076 - val_loss: 242.1198\n",
            "Epoch 192/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0389 - val_loss: 243.0940\n",
            "Epoch 193/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.1564 - val_loss: 242.2228\n",
            "Epoch 194/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0399 - val_loss: 242.0442\n",
            "Epoch 195/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0748 - val_loss: 242.1033\n",
            "Epoch 196/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 239.7214"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0385 - val_loss: 242.1639\n",
            "Epoch 197/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.0343 - val_loss: 242.4636\n",
            "Epoch 198/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 240.0586 - val_loss: 242.3990\n",
            "Epoch 199/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0648 - val_loss: 242.2125\n",
            "Epoch 200/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.9457 - val_loss: 242.3446\n",
            "Epoch 201/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 240.0584 - val_loss: 241.9544\n",
            "Epoch 202/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.9522 - val_loss: 242.4555\n",
            "Epoch 203/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 240.4215"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 115us/step - loss: 240.0663 - val_loss: 242.2213\n",
            "Epoch 204/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.9680 - val_loss: 242.0175\n",
            "Epoch 205/500\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 239.8796 - val_loss: 242.0576\n",
            "Epoch 206/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.8632 - val_loss: 242.3150\n",
            "Epoch 207/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.8730 - val_loss: 241.8403\n",
            "Epoch 208/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.7481 - val_loss: 242.1183\n",
            "Epoch 209/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.8467 - val_loss: 242.0317\n",
            "Epoch 210/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 239.4168"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.8429 - val_loss: 241.9608\n",
            "Epoch 211/500\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 239.8347 - val_loss: 241.8450\n",
            "Epoch 212/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.8161 - val_loss: 241.8846\n",
            "Epoch 213/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.9063 - val_loss: 241.9704\n",
            "Epoch 214/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.6908 - val_loss: 241.8960\n",
            "Epoch 215/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.7286 - val_loss: 242.2110\n",
            "Epoch 216/500\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 239.7765 - val_loss: 241.8928\n",
            "Epoch 217/500\n",
            "26624/60000 [============>.................] - ETA: 3s - loss: 240.1752"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 117us/step - loss: 239.6862 - val_loss: 241.8622\n",
            "Epoch 00217: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XsV4Fu2EfM3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = autoencoder.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GT93i35Anmey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "d1679d2e-e297-4b45-be66-5d37153e368a"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(pred[0].reshape(28, 28), cmap='gray')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f61d7c85048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f61d7bddac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uniLpXGDnsxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "67d2a89b-d723-4f2f-c6c6-934fe5a5f2ce"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0].reshape(28, 28), cmap='gray')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f61d49b6c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBACD/wOXYIFdrD0N0QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f61d7c29390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qYbAza8In0zG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rms(x,y):\n",
        "  a=(x^2-y^2)\n",
        "  return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGHgU2O5okzZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score=autoencoder.evaluate(pred,y_test,verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2r-31Dgxomy-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0FTDQ_KGqtPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}